#!/usr/bin/env python

from __future__ import print_function
import os
import sys
import requests


def usage():
    sys.exit(
        'Downloads this test suite\'s pytest JSON artifact to filepath.\n'
        'USAGE: {} filepath'.format(sys.argv[0])
    )

try:
    dl_fp = sys.argv[1]
except IndexError:
    usage()

ZEUS_BASE_URL = 'https://zeus.ci'
ZEUS_TOKEN = os.environ['ZEUS_TOKEN']
TEST_SUITE = os.environ['TEST_SUITE']

def rget(path, **kwargs):
    r = requests.get(
        ZEUS_BASE_URL + path,
        headers={
            'Authorization': 'Bearer {}'.format(ZEUS_TOKEN),
            'User-Agent': 'zeus-utils-get-pytest-artifact-' + requests.utils.default_user_agent()
        }, **kwargs
    )
    r.raise_for_status()
    return r

def good(build):
    return build['status'] == 'finished' and \
        build['result'] == 'passed'

'''
# get latest 50 (default) revisions/commits on master (default)
revisions = rget('/api/repos/gh/getsentry/sentry/revisions').json()

try:
    target_build = next(r for r in revisions if good(r['latest_build']))['latest_build']
except StopIteration:
    sys.exit(
        'Not a single successful build on master found in the last '
        '{} commits. Nice one!'.format(len(revisions))
    )
'''

print('getting artifact for build 9505')
#print('Retrieving artifact list for build #{} ({})'.format(
#    target_build['number'], target_build['label']))
artifacts = rget('/api/repos/gh/getsentry/sentry/builds/{}/artifacts'.format(
    9505)).json()
#    target_build['number'])).json()

try:
    # TODO cannot fully rely on identifying unique artifact by naming after test_suite
    # like, theres two postgres but one is using tagstore v2
    target_artifact_name = 'pytest-{}.json'.format(TEST_SUITE)
    target_artifact = next(a for a in artifacts if a['name'] == target_artifact_name)
except StopIteration:
    sys.exit('Could not find artifact {}.'.format(target_artifact_name))

print('Artifact {} found. Downloading to {}.'.format(target_artifact_name, dl_fp))
r = rget(target_artifact['download_url'], stream=True)
with open(dl_fp, 'wb') as f:
    for chunk in r.iter_content(1024):
        f.write(chunk)
